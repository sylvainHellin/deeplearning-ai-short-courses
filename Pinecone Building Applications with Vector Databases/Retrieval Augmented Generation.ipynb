{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"secrets.env\"))\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = \"deeplearning-ai-rag\"\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "\tpass\n",
    "else:\n",
    "\tpinecone.create_index(\n",
    "\t\tname=INDEX_NAME,\n",
    "\t\tdimension=1536,\n",
    "\t\tmetric=\"cosine\",\n",
    "\t\tspec=ServerlessSpec(\n",
    "\t\t\tcloud=\"aws\",\n",
    "\t\t\tregion=\"us-west-2\", #TODO update when europe available\n",
    "\t\t),\n",
    "\t)\n",
    "\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-0</td>\n",
       "      <td>{'chunk': 0, 'source': 'https://simple.wikiped...</td>\n",
       "      <td>[-0.011254455894231796, -0.01698738895356655, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           metadata  \\\n",
       "1  1-0  {'chunk': 0, 'source': 'https://simple.wikiped...   \n",
       "\n",
       "                                              values  \n",
       "1  [-0.011254455894231796, -0.01698738895356655, ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the dataset if necessary\n",
    "# !wget -q -O lesson2-wiki.csv.zip \"https://www.dropbox.com/scl/fi/yxzmsrv2sgl249zcspeqb/lesson2-wiki.csv.zip?rlkey=paehnoxjl3s5x53d1bedt4pmc&dl=0\"\n",
    "\n",
    "# !unzip lesson2-wiki.csv.zip\n",
    "\n",
    "# Load it\n",
    "CWD = os.getcwd()\n",
    "path = CWD + \"/files/wiki.csv\"\n",
    "MAX_NUM_ARTICLES = 10000 #TODO Play with this hyperparameter later on to see the influence on the quality of the results\n",
    "\n",
    "df = pd.read_csv(path, nrows=MAX_NUM_ARTICLES)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [07:04<00:00, 23.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def uploadDataToIndex(df, index):\n",
    "\n",
    "\t# prepare a list of embeddings to upload in the index\n",
    "\tpackage = []\n",
    "\n",
    "\t# populate the index\n",
    "\tfor i, row in tqdm(df.iterrows(), total=df.shape[0]): # iterate through the rows of the dataframe\n",
    "\t\t# fill up the package\n",
    "\t\tpackage.append({\n",
    "\t\t\t\"id\": row[\"id\"],\n",
    "\t\t\t\"values\": ast.literal_eval(row[\"values\"]),\n",
    "\t\t\t\"metadata\": ast.literal_eval(row[\"metadata\"]),\n",
    "\t\t})\n",
    "\n",
    "\t\t# once the package is big enough, upload it in the index\n",
    "\t\tif len(package) >= 250:\n",
    "\t\t\tindex.upsert(package) # upload the package\n",
    "\t\t\tpackage = [] # reset it\n",
    "\n",
    "\tif len(package) > 0:\n",
    "\t\tindex.upsert(package) # upload the package\n",
    "\t\tpackage = [] # reset it\n",
    "\n",
    "uploadDataToIndex(df=df, index=index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up openAI client\n",
    "openAI = OpenAI(api_key=OPENAI_API_KEY) # openAI client to interact with it's API\n",
    "\n",
    "\n",
    "def getEmbeddings(query:str):\n",
    "\t'''\n",
    "\tReturn the embedding of the query.\n",
    "\t'''\n",
    "\tmodel = \"text-embedding-3-small\"\n",
    "\treturn openAI.embeddings.create(input=query, model=model).data[0].embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Killing a living thing is when someone or something ends that life and makes the living thing die. It means causing a death. When a human being kills another human being, it is called murder or homicide, such as manslaughter.  \\n\\nPesticides and herbicides are poisons for killing bad wild small animals or plants, respectively.\\n\\nWhen a soldier kills another in war, it is called \"combat\".  When the state kills a convict sentenced to capital punishment, it is called execution. When someone kills a  powerful person it is called assassination. When a person who wants to die kills himself it is suicide, or euthanasia if killed by another. When people kill other people to eat them, it is called cannibalism.\\n\\nRelated pages \\n Cain and Abel\\n\\nCrime',\n",
       " 'Observances\\n Earliest day that Martin Luther King, Jr. Day can fall, while January 21 is the latest, on the third Monday in January (United States)\\n Armed Forces Day (Nigeria)\\n Army Day (India)\\n Tree Planting Day (Egypt)\\n\\nDays of the year',\n",
       " \"Observances \\n Independence Day (Namibia)\\n Human Rights Day (South Africa)\\n Benito Juarez' birthday (Mexico)\\n Spring Equinox – Northern Hemisphere\\n Autumn Equinox – Southern Hemisphere\\n International Day against racial discrimination (after Sharpeville massacre)\\n World Poetry Day\\n Youth Day (Tunisia)\\n Harmony Day (Australia)\\n World Down syndrome Day\\n Mother's Day (Most of the Arab World)\\n World Puppetry Day\\n International Colour Day\\n International Day of Forests\\n\\nDays of the year\"]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve context from index\n",
    "def retrieval(query):\n",
    "\t'''\n",
    "\treturn a list of 3 passages from index closest to the query\n",
    "\t'''\n",
    "\temd = getEmbeddings(query)\n",
    "\tresponse =  index.query(top_k=3, vector=emd, include_metadata=True)\n",
    "\tinfoList = []\n",
    "\tfor match in response.matches:\n",
    "\t\tinfoList.append(match.metadata[\"text\"])\n",
    "\treturn infoList\n",
    "\n",
    "# test\n",
    "query = \"what is the berlin wall?\"\n",
    "retrieval(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structurePrompt(query):\n",
    "\t'''\n",
    "\tStructure the prompt by adding context from our index to the query.\n",
    "\t'''\n",
    "\n",
    "\t# retrieve contect\n",
    "\tcontext = retrieval(query=query)\n",
    "\n",
    "\t# Structure the prompt\n",
    "\tpromptStart = \"\\\n",
    "\tAnswer the question based on the context below.\\n\\\n",
    "\t--------\\n\\\n",
    "\tContext:\\n\\\n",
    "\t--------\\n\"\n",
    "\n",
    "\tpromptEnd = f\"\\\n",
    "\t\\n--------\\n\\\n",
    "\tQuestion:\\n\\\n",
    "\t{query}\\n\\\n",
    "\t--------\\n\\\n",
    "\tAnswer:\\n\"\n",
    "\n",
    "\tprompt = promptStart + f\"\\n--------\\n\".join(context) + promptEnd\n",
    "\t\n",
    "\t# return the structured prompt\n",
    "\treturn prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Colors are visual perceptions that are created by the way light interacts with objects. They are typically described in terms of their hue, saturation, and brightness.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put everything together to get a working RAG\n",
    "def RAG(query):\n",
    "\tprompt = structurePrompt(query=query)\n",
    "\tmessages = [{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": prompt\n",
    "\t\t}]\n",
    "\tmodel = \"gpt-3.5-turbo-0125\"\n",
    "\tresponse = openAI.chat.completions.create(messages=messages, model=model, temperature=0, )\n",
    "\tresponseContent = response.choices[0].message.content\n",
    "\tresponseContent = responseContent if responseContent != None else \"\"\n",
    "\treturn responseContent\n",
    "\n",
    "# choose your query\n",
    "query = \"What are colors?\"\n",
    "\n",
    "# see RAG in action!\n",
    "RAG(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvPinecone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

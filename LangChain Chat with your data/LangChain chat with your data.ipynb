{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T20:07:40.735699Z",
     "start_time": "2024-01-24T20:07:40.207044Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"secrets.env\", raise_error_if_not_found=True))\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:38:21.311051Z",
     "start_time": "2024-01-24T19:38:18.550867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation in Construction 157 (2024) 105187\n",
      "Available online 11 November 2023\n",
      "0926-5805/© 2023 Elsevier B.V. All rights reserved.Review \n",
      "Generative AI design for building structures \n",
      "Wenjie Liaoa, Xinzheng Lua,*, Yifan Feib, Yi Gub, Yuli Huanga \n",
      "aKey Laboratory of Civil Engineering Safety and Durability of Ministry of Education, Tsinghua University, Beijing 100084, China \n",
      "bBeijing Engineering Research Center of Steel and Concrete Composite Structures, Tsinghua University, Beijing 100084, China \n",
      "\n",
      "source: Data/Generative AI design for building structures.pdf\n",
      "page: 0\n"
     ]
    }
   ],
   "source": [
    "# import the loader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# load the document\n",
    "loader = PyPDFLoader(file_path=\"Data/Generative AI design for building structures.pdf\")\n",
    "pages = loader.load()\n",
    "firstPage = pages[0]\n",
    "\n",
    "# see what's inside\n",
    "print(firstPage.page_content[:500])\n",
    "print(\"\")\n",
    "\n",
    "# see the metadata of this first page\n",
    "for k, v in firstPage.metadata.items():\n",
    "\tprint(f\"{k}: {v}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTube Loader\n",
    "\n",
    "Something is wrong with yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "# url of the video\n",
    "# url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "url=\"https://youtu.be/eHzoTLwx01E?si=xLkpwI4rvuW1FEpJ\"\n",
    "\n",
    "# local path to save audio\n",
    "path = \"Data/youtube/\"\n",
    "\n",
    "# build the generic loader with the youtube loader and the parser\n",
    "loader = GenericLoader(\n",
    "\tblob_loader=YoutubeAudioLoader(\n",
    "\t\turls=[url], #NB: urls argument must be a list\n",
    "\t\tsave_dir=path\n",
    "\t),\n",
    "\tblob_parser=OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "# load the youtube audio\n",
    "audioDoc = loader.load()\n",
    "\n",
    "# see what it understood\n",
    "print(audioDoc[:500])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:38:57.786439Z",
     "start_time": "2024-01-24T19:38:57.130100Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# url for the loader\n",
    "url = \"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\"\n",
    "\n",
    "# create the loader\n",
    "loader = WebBaseLoader(web_path=url)\n",
    "\n",
    "# load the page content\n",
    "webDoc = loader.load()\n",
    "\n",
    "# print the page content\n",
    "# print(webDoc[0].page_content[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:39:10.431282Z",
     "start_time": "2024-01-24T19:39:10.428437Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"secrets.env\", raise_error_if_not_found=True))\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:39:32.078343Z",
     "start_time": "2024-01-24T19:39:32.072384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursive splitting from text1 = ['abcdefghijklmnopqrstuvwxyz']\n",
      "character splitting from text1 = ['abcdefghijklmnopqrstuvwxyz']\n",
      "\n",
      "recursive splitting from text2 = ['abcdefghijklmnopqrstuvwxyz', 'qrstuvwxyzabcdefg']\n",
      "character splitting from text2 = ['abcdefghijklmnopqrstuvwxyz', 'qrstuvwxyzabcdefg']\n",
      "\n",
      "recursive splitting from text3 = ['a b c d e f g h i j k l m', 'i j k l m n o p q r s t u', 'q r s t u v w x y z']\n",
      "character splitting from text3 = ['a b c d e f g h i j k l m', 'i j k l m n o p q r s t u', 'q r s t u v w x y z']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size = 26\n",
    "chunk_overlap = 10\n",
    "\n",
    "recursiveSplitter = RecursiveCharacterTextSplitter(\n",
    "\tchunk_size = chunk_size,\n",
    "\tchunk_overlap = chunk_overlap,\n",
    ")\n",
    "\n",
    "characterSplitter = CharacterTextSplitter(\n",
    "\tchunk_size = chunk_size,\n",
    "\tchunk_overlap = chunk_overlap,\n",
    "\tseparator = \"\"\n",
    ")\n",
    "\n",
    "# first example\n",
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "print(f\"recursive splitting from text1 = {recursiveSplitter.split_text(text1)}\")\n",
    "print(f\"character splitting from text1 = {characterSplitter.split_text(text1)}\\n\")\n",
    "\n",
    "# second example\n",
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "print(f\"recursive splitting from text2 = {recursiveSplitter.split_text(text2)}\")\n",
    "print(f\"character splitting from text2 = {characterSplitter.split_text(text2)}\\n\")\n",
    "\n",
    "# third example\n",
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "print(f\"recursive splitting from text3 = {recursiveSplitter.split_text(text3)}\")\n",
    "print(f\"character splitting from text3 = {characterSplitter.split_text(text3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:39:38.349158Z",
     "start_time": "2024-01-24T19:39:38.337225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block: When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\n",
      "\n",
      "Block: closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\n",
      "\n",
      "Block: Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this\n",
      "\n",
      "Block: string. Sentences have a period at the end, but also, have a space.and words are separated by space.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More detailled regarding document splitting\n",
    "\n",
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "recursiveSplitter = RecursiveCharacterTextSplitter(\n",
    "\tchunk_size = 150,\n",
    "\tchunk_overlap = 0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "    # separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "[print(f\"Block: {txt}\\n\") for txt in recursiveSplitter.split_text(some_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Token splitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:54:16.408214Z",
     "start_time": "2024-01-24T19:54:16.396177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[\"coucou c'est moi!\"]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "textSplitter1 = TokenTextSplitter(\n",
    "\tchunk_size=1,\n",
    "\tchunk_overlap=0\n",
    ")\n",
    "\n",
    "text1 = \"coucou c'est moi!\"\n",
    "\n",
    "textSplitter1.split_text(text1)\n",
    "\n",
    "textSplitter2 = TokenTextSplitter(\n",
    "\tchunk_size = 10,\n",
    "\tchunk_overlap = 0\n",
    ")\n",
    "\n",
    "textSplitter2.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'source': 'Data/Generative AI design for building structures.pdf', 'page': 0}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = textSplitter2.split_documents(pages)\n",
    "docs[0].metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T19:56:35.103737Z",
     "start_time": "2024-01-24T19:56:35.050606Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context aware splitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdownDoc = '''# Artificial Intelligence\n",
    "\n",
    "## Interesting Articles\n",
    "\n",
    "### AI for Architecture\n",
    "\n",
    "- [7 Top AI Tools for Generating Smart Architectural Plans](https://architizer.com/blog/practice/tools/top-ai-tools-for-generating-architectural-plans/)\n",
    "\n",
    "## Interesting AI tools\n",
    "\n",
    "- perplexity.ai : give concise answers to question while citing source\n",
    "- lumalabs: create 3d représentation based on a video\n",
    "- scispace: use to get answer only based on research papers content. can also be used to help understand paper (like summarize complex topics)\n",
    "- google SGE: similar to perplexity, but from google\n",
    "- '''\n",
    "\n",
    "headerToSplittOn = [\n",
    "\t(\"#\", \"Header 1\"),\n",
    "\t(\"##\", \"Header 2\"),\n",
    "\t(\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdownSplitter = MarkdownHeaderTextSplitter(\n",
    "\theaders_to_split_on = headerToSplittOn\n",
    ")\n",
    "\n",
    "splittedMD = markdownSplitter.split_text(markdownDoc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T20:49:18.921942Z",
     "start_time": "2024-01-24T20:49:18.918304Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearningVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

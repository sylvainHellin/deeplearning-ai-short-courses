{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image generation with Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as IPythonImage\n",
    "import gradio as gr\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(filename=\"secrets.env\", raise_error_if_not_found=True))\n",
    "ROOT_DIR = os.environ[\"ROOT_DIR\"]\n",
    "HF_API_TOKEN = os.environ[\"HF_API_TOKEN\"]\n",
    "HF_MODEL = \"runwayml/stable-diffusion-v1-5\"\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{HF_MODEL}\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {HF_API_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query(payload):\n",
    "# \tresponse = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "# \timage_bytes = response.content\n",
    "# \treturn image_bytes\n",
    "\n",
    "# image_bytes = query({\n",
    "# \t\"inputs\": \"a cat on the back of a dinausor\",\n",
    "# })\n",
    "\n",
    "# image = Image.open(io.BytesIO(image_bytes))\n",
    "# path = ROOT_DIR + \"/files/gen_img.png\"\n",
    "# image.save(path, format=\"png\")\n",
    "# IPythonImage(path)\n",
    "# display(IPythonImage(image_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and test the completion function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple app usiong Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API call\n",
    "def generate(prompt:str):\n",
    "    response = requests.post(url=API_URL, headers=HEADERS, json=prompt)\n",
    "    return Image.open(io.BytesIO(response.content))\n",
    "\n",
    "gr.close_all()\n",
    "app = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=gr.Textbox(label=\"Enter your prompt\"),\n",
    "    outputs=gr.Image(label=\"Generated image\", type=\"pil\"),\n",
    "    title=\"Image generator\",\n",
    "    description=\"Generate an image for a given prompt, powered by 'stable-diffusion-v1-5'\",\n",
    "    allow_flagging=\"never\",\n",
    "    examples=[\"a friendly lama eating popcorn and watching a movie, in a cartoon style\"],\n",
    ")\n",
    "\n",
    "# app.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a more advanced app using Blocks and Accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the API call to take additional parameters\n",
    "def API_call(inputs:str, parameters = None, url = API_URL):\n",
    "\t\n",
    "\t# create the payload (the prompt)\n",
    "\tpayload = {\"inputs\": inputs}\n",
    "\t\n",
    "\t# update it with more detailled parameters if available\n",
    "\tif parameters != None:\n",
    "\t\tpayload.update({\"parameters\": parameters})\n",
    "\t\n",
    "\t# send the request\n",
    "\tresponse = requests.post(url=url, json=payload, headers=HEADERS)\n",
    "\n",
    "\t# extract the output from the response\n",
    "\timageBytes = response.content\n",
    "\n",
    "\t# return it\n",
    "\treturn imageBytes\n",
    "\n",
    "# update the generate function to accept these additional parameters\n",
    "def generate(prompt:str, negative_prompt:str=\"\", steps:int=25, guidance:int=7, width:int=512, height:int=512):\n",
    "\t# format the parameters for the API call\n",
    "\tparameters = {\n",
    "\t\t\"negative_prompt\" : negative_prompt,\n",
    "\t\t\"num_inference_steps\": steps,\n",
    "\t\t\"guidance_scale\": guidance,\n",
    "\t\t\"width\": width,\n",
    "\t\t\"height\": height,\n",
    "\t}\n",
    "\n",
    "\t# make the API call\n",
    "\tImageByte = API_call(inputs=prompt, parameters=parameters)\n",
    "\t\n",
    "\t# convert to PIL format\n",
    "\toutput = Image.open(io.BytesIO(ImageByte))\n",
    "\n",
    "\t# return the output\n",
    "\treturn output\n",
    "\n",
    "# Create the advanced app\n",
    "with gr.Blocks(theme = gr.themes.Monochrome()) as app:\n",
    "\t# Title and description\n",
    "\tgr.Markdown(\"# Image generation app\")\n",
    "\tgr.Markdown(\"Powered by stable-diffusion-v1.5 under the hood\")\n",
    "\t\n",
    "\t# First row: prompt and button side by side\n",
    "\twith gr.Row():\n",
    "\t\twith gr.Column(scale=5):\n",
    "\t\t\tprompt = gr.Textbox(label=\"Enter your prompt\", scale=5)\n",
    "\t\twith gr.Column(scale=1):\n",
    "\t\t\tbutton = gr.Button(value=\"submit\", min_width=30, scale=1)\n",
    "\t\n",
    "\t# Second row: allow for advanced customization\n",
    "\twith gr.Accordion(label=\"Advanced option\", open=False): # should not be visible by default\n",
    "\t\t\n",
    "\t\t# first row: negative prompt\n",
    "\t\tnegativePrompt = gr.Textbox(label=\"Negative Prompt\", value=\"low quality\")\n",
    "\n",
    "\t\t# second row: two columns of advanced options\n",
    "\t\twith gr.Row():\n",
    "\t\t\twith gr.Column():\n",
    "\t\t\t\tgr.Markdown(\"Parameters for the image generator\")\n",
    "\t\t\t\tsteps = gr.Slider(\n",
    "\t\t\t\t\tlabel=\"Inference steps\",\n",
    "\t\t\t\t\tminimum=1,\n",
    "\t\t\t\t\tmaximum=100,\n",
    "\t\t\t\t\tvalue=25,\n",
    "\t\t\t\t\tstep=1,\n",
    "\t\t\t\t\tinfo = \"In how many steps should the denoiser generate the image?\"\n",
    "\t\t\t\t)\n",
    "\t\t\t\tguidance = gr.Slider(\n",
    "\t\t\t\t\tlabel=\"Generation guidance\",\n",
    "\t\t\t\t\tminimum=1,\n",
    "\t\t\t\t\tmaximum=25,\n",
    "\t\t\t\t\tvalue=7,\n",
    "\t\t\t\t\tstep=1,\n",
    "\t\t\t\t\tinfo = \"How much should the prompt influence the generation?\"\n",
    "\t\t\t\t)\n",
    "\t\t\twith gr.Column():\n",
    "\t\t\t\tgr.Markdown(\"Size of the generated image\")\n",
    "\t\t\t\twidth = gr.Slider(\n",
    "\t\t\t\t\tlabel=\"Width\",\n",
    "\t\t\t\t\tminimum=64,\n",
    "\t\t\t\t\tmaximum=512,\n",
    "\t\t\t\t\tstep=64,\n",
    "\t\t\t\t\tvalue=512,\n",
    "\t\t\t\t\tinfo=\"Expected width of the generated image\",\n",
    "\t\t\t\t)\n",
    "\t\t\t\theight = gr.Slider(\n",
    "\t\t\t\t\tlabel=\"Height\",\n",
    "\t\t\t\t\tminimum=64,\n",
    "\t\t\t\t\tmaximum=512,\n",
    "\t\t\t\t\tstep=64,\n",
    "\t\t\t\t\tvalue=512,\n",
    "\t\t\t\t\tinfo=\"Expected height of the generated image\",\n",
    "\t\t\t\t)\n",
    "\t# next row: result (generated image)\n",
    "\toutputs = gr.Image(label=\"Result\", type=\"pil\")\n",
    "\t\n",
    "\t# define the logic of the app\n",
    "\tbutton.click(\n",
    "\t\tfn=generate,\n",
    "\t\tinputs=[prompt, negativePrompt, steps, guidance, width, height],\n",
    "\t\t# inputs=[prompt],\n",
    "\t\toutputs=outputs,\n",
    "\t)\n",
    "\n",
    "# gr.close_all()\n",
    "# app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing image generation with DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-pdvcmVDA9DWs0Dj2mhB4jBPg/user-2BBJ7cZHy9ZSGf7qwQDMYEZb/img-83RubD1TfNFjlrEOUs6jmGuz.png?st=2024-02-14T20%3A48%3A24Z&se=2024-02-14T22%3A48%3A24Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-02-14T17%3A22%3A10Z&ske=2024-02-15T17%3A22%3A10Z&sks=b&skv=2021-08-06&sig=H8MZrRu9/r/mzPicRprhmqSacQJy3KcNjD1Uz%2B56GjA%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# prompt = \"A futuristic vision of the city of Munich in year 2100\"\n",
    "prompt = \"A futuristic but realistic vision of Munich's Tucherpark in year 2100\"\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=prompt,\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "IPythonImage(url=image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScienceVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
